{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện trên bộ dữ liệu ViCTSD\n",
    "* Là dữ liệu thu thập được từ các bài báo\n",
    "* Bình luận không mang nặng xu hướng công kích cá nhân, mà thiên vì phát biểu cảm nghĩ, đưa ra ý kiến"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../Dataset_Cleaned/clean_train_victsd.csv'\n",
    "DEV_PATH = '../Dataset_Cleaned/dev_victsd.csv'\n",
    "TEST_PATH = '../Dataset_Cleaned/test_victsd.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "dev = pd.read_csv(DEV_PATH)\n",
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "* Tokenize\n",
    "* Remove stopwords\n",
    "* pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup functions to preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word seqmentation\n",
    "# ML không bắt buộc seqmentation\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Thật tuyệt vời -> Thật tuyệt_vời\n",
    "    \"\"\"\n",
    "    return ViTokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('..\\Stopwords\\\\vietnamese-stopwords-dash.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = [line.strip() for line in f]\n",
    "\n",
    "# Loại các từ stopwords không hợp lí - ảnh hưởng nhiều tới ý nghĩa câu\n",
    "sus_stopwords = [\"không\",\"không_có\",\"không_thể\",\"chưa\"]\n",
    "for sus_stopword in sus_stopwords:\n",
    "  stopwords.remove(sus_stopword)\n",
    "\n",
    "\n",
    "def lower_and_remove_stopwords(text: str):\n",
    "    \"\"\"\n",
    "    Loại bỏ các từ stopwords và chuyển văn bản về chữ thường\n",
    "    Đây là con_chó -> con_chó\"\"\"\n",
    "    # Chuyển đổi văn bản sang chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tách văn bản thành danh sách các từ\n",
    "    words = text.split()\n",
    "\n",
    "    # Loại bỏ stopword\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    # Ghép danh sách các từ đã lọc lại thành văn bản\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_links_hashtag_tag(text):\n",
    "    \"\"\"\n",
    "    Removes URLs from a text string.\n",
    "\n",
    "    Args:\n",
    "        text: The text string to process.\n",
    "\n",
    "    Returns:\n",
    "        The text string with URLs removed.\n",
    "    \"\"\"\n",
    "    link_remover = r\"(https?://[^\\s]+)\"\n",
    "    hashtag_remover = r\"# [^\\s]+\"\n",
    "    tag_remover = r\"@ [^\\s]+\"\n",
    "\n",
    "    text = re.sub(link_remover, \"\", text)\n",
    "    text = re.sub(hashtag_remover, \"\", text)\n",
    "    text = re.sub(tag_remover, \"\", text)\n",
    "  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dữ liệu sau khi process dạng text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"bánh này không ngon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bánh này không ngon'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = ViTokenizer.tokenize(test_text)\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: bánh này không ngon\n",
      "After: bánh không ngon\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before: {test_text}\")\n",
    "test_text = lower_and_remove_stopwords(test_text)\n",
    "test_text = remove_links_hashtag_tag(test_text)\n",
    "print(f\"After: {test_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text and label each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text'].astype(str)\n",
    "y_train = train['label']\n",
    "X_dev = dev['text'].astype(str)\n",
    "y_dev = dev['label']\n",
    "X_test = test['text'].astype(str)\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       thật tuyệt vời\n",
       "1    mỹ đã tuột dốc quá nhiều rồi giờ muốn vực dậy ...\n",
       "2    tôi thấy người lái xe hơi bấm còi mới là người...\n",
       "3    coi dịch là giặc đã mang tên đó mà xâm nhập vn...\n",
       "4    thương các bé quá các con còn quá nhỏ mà đã ph...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, test\n",
    "\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(path):\n",
    "    \"\"\"\n",
    "    1. Get data from paths\n",
    "    3. Tokenize -> lower and remove stopwords -> remove links, hashtags, tags\n",
    "    4. Get X, y from dataframe (input, output)\n",
    "    \"\"\"\n",
    "    train_data = pd.read_csv(path)[['text', 'label']]\n",
    "    df_joined = pd.concat([train_data], ignore_index=True)\n",
    "    df_joined['text'] = df_joined['text'].astype(str)\n",
    "    df_joined['text'] = df_joined['text'].apply(tokenize)\n",
    "    df_joined['text'] = df_joined['text'].apply(lower_and_remove_stopwords)\n",
    "    df_joined['text'] = df_joined['text'].apply(remove_links_hashtag_tag)\n",
    "    X = df_joined['text']\n",
    "    y = df_joined['label'].tolist()\n",
    "    return X, y, df_joined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_data = preprocess_data(TRAIN_PATH)\n",
    "X_dev, y_dev, dev_data = preprocess_data(DEV_PATH)\n",
    "X_test_, y_test_, test_data = preprocess_data(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            tuyệt_vời\n",
       "1                                  mỹ tuột_dốc vực dậy\n",
       "2    lái xe_hơi bấm còi lịch_sự văn minhđường_xá ch...\n",
       "3    coi dịch giặc xâm_nhập vn đầu_hàng cút xéo vn ...\n",
       "4    thương bé rời cha_mẹ chia buồn gia_đình cầu_mo...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Để lấy dữ liệu cho nhanh chứ ko up lên git\n",
    "train_data.to_csv('preprocessed_train_data.csv', index=False)\n",
    "dev_data.to_csv('preprocessed_dev_data.csv', index=False)\n",
    "test_data.to_csv('preprocessed_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size=50000\n",
    "embedding_dim=64\n",
    "max_length=140\n",
    "\n",
    "train_data = pd.read_csv('preprocessed_train_data.csv')\n",
    "dev_data = pd.read_csv('preprocessed_dev_data.csv')\n",
    "test_data = pd.read_csv('preprocessed_test_data.csv')\n",
    "\n",
    "X_train, y_train = train_data['text'].astype(str), train_data['label']\n",
    "X_val, y_val = dev_data['text'].astype(str), dev_data['label']\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post',truncating='post')\n",
    "\n",
    "# Thực hiện thay đổi test để đưa vào tính toán val_acc\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, maxlen=max_length, padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  y_pred_rounded = torch.round(y_pred)  \n",
    "  correct = torch.eq(y_true, y_pred_rounded).sum().item()\n",
    "  acc = (correct/len(y_pred))*100\n",
    "  return acc\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "def f1_score_fn(y_true, y_pred):\n",
    "  y_true = y_true.int()\n",
    "  y_pred = torch.round(y_pred)\n",
    "  y_pred = y_pred.int()\n",
    "  y_true=y_true.tolist()\n",
    "  y_pred = y_pred.tolist()\n",
    "  f1_score_value = f1_score(y_true=y_true, y_pred=y_pred, pos_label=1, zero_division=0)\n",
    "  # print(classification_report(y_true=y_true, y_pred=y_pred,zero_division=1))  \n",
    "  return f1_score_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907258064516129"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "tmp1 = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
    "tmp2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "f1_score(tmp1, tmp2, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_encoded: np.ndarray, y_encoded: pd.core.series.Series):\n",
    "        # Setup\n",
    "        self.x_encoded = x_encoded\n",
    "        self.y_encoded = y_encoded.tolist()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.FloatTensor(self.x_encoded[idx]), self.y_encoded[idx])\n",
    "        # return (self.x_encoded[idx], self.y_encoded[idx])\n",
    "        # return {'text': self.x[idx], 'label': self.y_encoded[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_encoded.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(X_train, y_train)\n",
    "test_data = CustomDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6970"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE=32\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2a07a96ea50>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocal_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocal_size, embedding_dim=embedding_dim )\n",
    "        self.lstm = nn.LSTM(embedding_dim , hidden_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.activate1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.se = nn.Sequential(\n",
    "            nn.Embedding(num_embeddings=vocal_size, embedding_dim=embedding_dim),\n",
    "            nn.LSTM(embedding_dim , hidden_dim, batch_first=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            # nn.ReLU(),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activate1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        # print(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(50000, 64)\n",
       "  (lstm): LSTM(64, 16, batch_first=True)\n",
       "  (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (activate1): ReLU()\n",
       "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (activate2): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (se): Sequential(\n",
       "    (0): Embedding(50000, 64)\n",
       "    (1): LSTM(64, 16, batch_first=True)\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (5): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Model = LSTMModel(vocal_size=vocab_size, embedding_dim=embedding_dim, hidden_dim=16, output_dim=1)\n",
    "LSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(LSTM_Model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092395165acd4f5e8c6cece338b2f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "------\n",
      "\n",
      "Train loss: 0.5444 | Test loss: 0.5775, Test acc: 88.4425, F1 score: 0.0000\n",
      "Epoch: 1\n",
      "------\n",
      "\n",
      "Train loss: 0.5444 | Test loss: 0.5824, Test acc: 88.3433, F1 score: 0.0000\n",
      "Epoch: 2\n",
      "------\n",
      "\n",
      "Train loss: 0.5445 | Test loss: 0.5799, Test acc: 88.3929, F1 score: 0.0000\n",
      "Epoch: 3\n",
      "------\n",
      "\n",
      "Train loss: 0.5444 | Test loss: 0.5799, Test acc: 88.3929, F1 score: 0.0000\n",
      "Epoch: 4\n",
      "------\n",
      "\n",
      "Train loss: 0.5440 | Test loss: 0.5799, Test acc: 88.3929, F1 score: 0.0000\n",
      "Epoch: 5\n",
      "------\n",
      "\n",
      "Train loss: 0.5444 | Test loss: 0.5824, Test acc: 88.3433, F1 score: 0.0000\n",
      "Epoch: 6\n",
      "------\n",
      "\n",
      "Train loss: 0.5450 | Test loss: 0.5775, Test acc: 88.4425, F1 score: 0.0000\n",
      "Epoch: 7\n",
      "------\n",
      "\n",
      "Train loss: 0.5442 | Test loss: 0.5799, Test acc: 88.3929, F1 score: 0.0000\n",
      "Epoch: 8\n",
      "------\n",
      "\n",
      "Train loss: 0.5442 | Test loss: 0.5799, Test acc: 88.3929, F1 score: 0.0000\n",
      "Epoch: 9\n",
      "------\n",
      "\n",
      "Train loss: 0.5447 | Test loss: 0.5799, Test acc: 88.3929, F1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Write a training and evaluationg loop for model_1\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Train for longer\n",
    "epochs = 10\n",
    "\n",
    "# # Put data on the target device\n",
    "# X_padded_sequences, y_train = torch.tensor(X_padded_sequences).to(device), torch.tensor(y_train).to(device)\n",
    "# padded_val_sequences, y_test=  torch.tensor(padded_val_sequences).to(device), torch.tensor(y_test).to(device)\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n------\")\n",
    "  ### Training\n",
    "  train_loss=0\n",
    "  LSTM_Model.train()\n",
    "  # Add a loop to loop through the training batches\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    # print(f\"Batch: {batch}\")\n",
    "\n",
    "    # 1. Forward\n",
    "    X = X.long()\n",
    "    y_pred = LSTM_Model(X)\n",
    "\n",
    "    # 2. Calculate the loss\n",
    "    y_pred_record.append(y_pred)\n",
    "    loss = loss_fn(y_pred.squeeze(), y.float().squeeze())\n",
    "    train_loss += loss\n",
    "\n",
    "    # 3.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4.\n",
    "    loss.backward()\n",
    "\n",
    "    # 5.\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print out what's happening\n",
    "    # if batch %50==0:\n",
    "    #   print(f\"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "\n",
    "  # Divide total train loss by length of train dataloader\n",
    "  train_loss /= len(train_dataloader)\n",
    "\n",
    "  ### Testing\n",
    "  test_loss, test_acc, avg_f1_score = 0,0,0\n",
    "  LSTM_Model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X_test_, y_test_ in test_dataloader:\n",
    "      # 1. Forward pass\n",
    "      X_test_ = X_test_.long()\n",
    "      test_pred = LSTM_Model(X_test_)\n",
    "\n",
    "      # 2. Calculate the loss (accumulatively)\n",
    "      test_loss += loss_fn(test_pred.squeeze(dim=1), y_test_.float())\n",
    "      # print(test_pred.shape)\n",
    "      # 3. Calculate accuracy\n",
    "      test_acc += accuracy_fn(y_true= y_test_.float(),\n",
    "                              y_pred = test_pred.squeeze(dim=1))\n",
    "      # 4. Calculate f1 score\n",
    "      avg_f1_score += f1_score_fn(y_true= y_test_.float(),\n",
    "                              y_pred = test_pred.squeeze(dim=1))\n",
    "    # Calculate the test loss average per batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "    avg_f1_score /= len(test_dataloader)\n",
    "    # Calculate the test acc average per batch\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "  # print out what happen\n",
    "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}, F1 score: {avg_f1_score:.4f}\")\n",
    "  # print(f\"\\nTrain loss; {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Model.state_dict(), 'LSTM.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model = LSTMModel(vocal_size=vocab_size, embedding_dim=embedding_dim, hidden_dim=16, output_dim=1)\n",
    "predict_model.load_state_dict(torch.load('LSTM.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nhập câu muốn dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictV1(test_sentences):\n",
    "    \"\"\"\n",
    "    Dùng model lưu để đánh giá test\n",
    "    \"\"\"\n",
    "    test_seq = tokenize(test_sentences)\n",
    "    test_seq = lower_and_remove_stopwords(test_seq)\n",
    "    test_seq = remove_links_hashtag_tag(test_seq)\n",
    "    test_seq = tokenizer.texts_to_sequences([test_seq])\n",
    "    # print(test_seq)\n",
    "    test_seq = pad_sequences(test_seq, maxlen=max_length, padding='post',truncating='post')\n",
    "    # print(test_seq)\n",
    "    return predict_model(torch.tensor(test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictV2(test_sentences):\n",
    "    \"\"\"\n",
    "    Dùng model đang huấn luyện để đánh giá test\n",
    "    \"\"\"\n",
    "    test_seq = tokenize(test_sentences)\n",
    "    test_seq = lower_and_remove_stopwords(test_seq)\n",
    "    test_seq = remove_links_hashtag_tag(test_seq)\n",
    "    test_seq = tokenizer.texts_to_sequences([test_seq])\n",
    "    # print(test_seq)\n",
    "    test_seq = pad_sequences(test_seq, maxlen=max_length, padding='post',truncating='post')\n",
    "    # print(test_seq)\n",
    "    return LSTM_Model(torch.tensor(test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>không kẻ chẳng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đạp xe văn_minh . haizzzz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>văn_hoá</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>đời ta mươi đời . mua xe phục_vụ đi_lại . linh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tước lái vĩnh_viễn đi . chạy lếu_láo , không c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>biệt_thự nhà_riêng to_đùng kia chủ ( ) đỗ xe k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ló khôn , tài cống_hiến tuyệt_vời xuất_sắc . b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>bánh trung_thu trứng muối . trẻ_con không bánh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1 lớp 1 cải_cách . mục_tiêu gd tiểu_học làm_qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0                                       không kẻ chẳng      1\n",
       "1                            đạp xe văn_minh . haizzzz      1\n",
       "2                                              văn_hoá      0\n",
       "3    đời ta mươi đời . mua xe phục_vụ đi_lại . linh...      0\n",
       "4    tước lái vĩnh_viễn đi . chạy lếu_láo , không c...      1\n",
       "..                                                 ...    ...\n",
       "995  biệt_thự nhà_riêng to_đùng kia chủ ( ) đỗ xe k...      1\n",
       "996  ló khôn , tài cống_hiến tuyệt_vời xuất_sắc . b...      0\n",
       "997  bánh trung_thu trứng muối . trẻ_con không bánh...      0\n",
       "998  1 lớp 1 cải_cách . mục_tiêu gd tiểu_học làm_qu...      0\n",
       "999                                                  .      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('preprocessed_test_data.csv')\n",
    "\n",
    "X_test, y_test = test_data['text'].astype(str), test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       không kẻ chẳng\n",
       "1                            đạp xe văn_minh . haizzzz\n",
       "2                                              văn_hoá\n",
       "3    đời ta mươi đời . mua xe phục_vụ đi_lại . linh...\n",
       "4    tước lái vĩnh_viễn đi . chạy lếu_láo , không c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0071]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "num_record = len(X_test)\n",
    "is_true = 0\n",
    "true_0 = 0\n",
    "false_0 = 0\n",
    "true_1 = 0\n",
    "false_1 = 0\n",
    "test_predict = []\n",
    "for i in range(len(X_test)):\n",
    "    if predictV2(X_test[i])<0.5:\n",
    "        test_predict.append(0)\n",
    "        if y_test[i] == 0:\n",
    "            true_0 += 1\n",
    "            is_true += 1\n",
    "        else:\n",
    "            false_0 += 1\n",
    "    else:\n",
    "        test_predict.append(1)\n",
    "        if y_test[i] == 1:\n",
    "            true_1 += 1\n",
    "            is_true += 1\n",
    "        else:\n",
    "            false_1 += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 890, 890, 0, 110, 0)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_record, is_true, true_0, true_1,false_0 ,false_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       890\n",
      "           1       0.00      0.00      0.00       110\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.45      0.50      0.47      1000\n",
      "weighted avg       0.79      0.89      0.84      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.708"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6708/num_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Đồ ngu, sao mày ngu thế?\", 1\n",
    "# \"Con này xấu xí, béo ú, chẳng ra gì cả.\", 1\n",
    "# \"Đồ đàn bà con gái chỉ biết ăn bám đàn ông.\",\n",
    "# \"Sản phẩm này tệ hại, ai mua cũng hối hận.\",\n",
    "# \"Mày hát dở tệ, đừng bao giờ hát nữa nhé.\", 0 \n",
    "# \"Mày dám nói tao ngu à? Thử lặp lại lần nữa xem!\",\n",
    "# \"Đời mày xuống lỗ rồi con ạ\", 0\n",
    "# \"Ngu thì nín :))\",\n",
    "# \"khôn như vợ chồng nhà này k biết bao giờ mới giỗ đầu bạn nhỉ :))\", 0 \n",
    "# \"toàn cái bọn lúc vay muốn dc vc.khi xong vc rồi thì vẩy đuôi b oi.g\n",
    "# \"sản phẩm này bố ỉa vào mà mua\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# filename = \"E:\\\\AI Project\\\\word2vec_vi_syllables_100dims.txt\"\n",
    "# chunksize = 10 ** 6\n",
    "# for chunk in pd.read_csv(filename, chunksize=chunksize, on_bad_lines='skip', quoting=csv.QUOTE_NONE, encoding='utf-8'):\n",
    "#     # chunk is a DataFrame. To \"process\" the rows in the chunk:\n",
    "#     for index, row in chunk.iterrows():\n",
    "#         print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
