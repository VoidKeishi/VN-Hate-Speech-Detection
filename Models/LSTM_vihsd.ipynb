{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện trên bộ dữ liệu ViHSD\n",
    "* Bao gồm dữ liệu thu thập từ mạng xã hội\n",
    "* Dữ liệu có tính toxic cao - phân biệt chủng tộc, vùng miền, công kích cá nhân, chửi đổng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # type: ignore\n",
    "import string\n",
    "import emoji_vietnamese  # type: ignore\n",
    "\n",
    "def load_data(dataset='vihsd'):\n",
    "    if dataset == 'vihsd':\n",
    "        train = pd.read_csv('../Dataset_Reformat/train_vihsd.csv')\n",
    "        dev = pd.read_csv('../Dataset_Reformat/dev_vihsd.csv')\n",
    "        test = pd.read_csv('../Dataset_Reformat/test_vihsd.csv')\n",
    "        train['label'], dev['label'], test['label'] = train['label'].replace(2,1), dev['label'].replace(2,1), test['label'].replace(2,1)\n",
    "    elif dataset == 'victsd':\n",
    "        train = pd.read_csv('../Dataset_Reformat/train_victsd.csv')\n",
    "        dev = pd.read_csv('../Dataset_Reformat/dev_victsd.csv')\n",
    "        test = pd.read_csv('../Dataset_Reformat/test_victsd.csv')\n",
    "    elif dataset == 'merged':\n",
    "        train = pd.read_csv('../Dataset_Reformat/train_merged.csv')\n",
    "        dev = pd.read_csv('../Dataset_Reformat/dev_merged.csv')\n",
    "        test = pd.read_csv('../Dataset_Reformat/test_merged.csv')\n",
    "        train['label'], dev['label'], test['label'] = train['label'].replace(2,1), dev['label'].replace(2,1), test['label'].replace(2,1)\n",
    "    return train, dev, test\n",
    "\n",
    "\n",
    "def preprocess_data(\n",
    "    data,\n",
    "    url=True,\n",
    "    punctuation=True,\n",
    "    lowercase=True,\n",
    "    stopword=False,\n",
    "    special_stopwords=[],\n",
    "    emoji=False\n",
    "):\n",
    "    # Load stopwords\n",
    "    with open('./utility/Stopwords/vietnamese-stopwords-dash.txt', 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "    for word in special_stopwords:\n",
    "        stopwords.remove(word)\n",
    "    # Function to remove stopwords\n",
    "    def remove_stopwords(text):\n",
    "        words = text.split()\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        return ' '.join(words)\n",
    "    if url:\n",
    "        # Remove URLs\n",
    "        data['text'] = data['text'].str.replace(\n",
    "            r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "    if punctuation:\n",
    "        # Remove punctuation\n",
    "        data['text'] = data['text'].str.replace(\n",
    "            '['+string.punctuation+']', '', regex=True)\n",
    "    if lowercase:\n",
    "        # Lowercase\n",
    "        data['text'] = data['text'].str.lower()\n",
    "    if stopword:\n",
    "        # Remove stopword\n",
    "        data['text'] = data['text'].apply(remove_stopwords)\n",
    "    if emoji:\n",
    "        # Remove emojis\n",
    "        data['text'] = data['text'].apply(emoji_vietnamese.demojize)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train, dev, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_data(dataset='vihsd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "* Remove url in comment\n",
    "* remove punctuation\n",
    "* Lowercase data\n",
    "* Remove stopwords\n",
    "* Remove emoji\n",
    "* Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_stopwords = [\"không\",\"không_có\",\"không_thể\",\"chưa\", \"được\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_preprocess = preprocess_data(dev,\n",
    "                                 url=True,\n",
    "                                 punctuation=True,\n",
    "                                 lowercase=True,\n",
    "                                 stopword=True,\n",
    "                                 special_stopwords=special_stopwords,\n",
    "                                 emoji=True)\n",
    "train_preprocess = preprocess_data(train,\n",
    "                                   url=True,\n",
    "                                   punctuation=True,\n",
    "                                   lowercase=True,\n",
    "                                   stopword=True,\n",
    "                                   special_stopwords=special_stopwords,\n",
    "                                   emoji=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocess = preprocess_data(test,\n",
    "                                    url=True,\n",
    "                                    punctuation=True,\n",
    "                                    lowercase=True,\n",
    "                                    stopword=True,\n",
    "                                    special_stopwords=special_stopwords,\n",
    "                                    emoji=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>được fan cứng nè :bộ chọn trái tim màu đỏ: rea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bọn mắt híp lò xo thụt việt nam t 10 r bọn t g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đậu văn cường thằng sida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>côn đồ cục súc vô nhân đề nghi vn vn ban thưởng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lý thuyết thực hành 1 câu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  được fan cứng nè :bộ chọn trái tim màu đỏ: rea...      0\n",
       "1  bọn mắt híp lò xo thụt việt nam t 10 r bọn t g...      1\n",
       "2                           đậu văn cường thằng sida      0\n",
       "3    côn đồ cục súc vô nhân đề nghi vn vn ban thưởng      1\n",
       "4                          lý thuyết thực hành 1 câu      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocess[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text and label each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text'].astype(str)\n",
    "y_train = train['label']\n",
    "X_dev = dev['text'].astype(str)\n",
    "y_dev = dev['label']\n",
    "X_test = test['text'].astype(str)\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Để lấy dữ liệu cho nhanh chứ ko up lên git\n",
    "train_preprocess.to_csv('preprocessed_train_data.csv', index=False)\n",
    "dev_preprocess.to_csv('preprocessed_dev_data.csv', index=False)\n",
    "test.to_csv('preprocessed_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "vocab_size=50000\n",
    "embedding_dim=128\n",
    "max_length=128\n",
    "\n",
    "train_data = pd.read_csv('preprocessed_train_data.csv')\n",
    "dev_data = pd.read_csv('preprocessed_dev_data.csv')\n",
    "test_data = pd.read_csv('preprocessed_test_data.csv')\n",
    "\n",
    "# X_train, y_train,_,_ = train_test_split(train_data['text'], train_data['label'], test_size=0.99, random_state=42)\n",
    "# X_val, y_val,_,_ = train_test_split(dev_data['text'], dev_data['label'], test_size=0.99, random_state=42)\n",
    "# X_train= X_train.astype(str)\n",
    "# X_val= X_val.astype(str)\n",
    "\n",
    "X_train, y_train = train_data['text'].astype(str), train_data['label']\n",
    "X_val, y_val = dev_data['text'].astype(str), dev_data['label']\n",
    "X_test, y_test = test_data['text'].astype(str), test_data['label']\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post',truncating='post')\n",
    "\n",
    "# Thực hiện thay đổi test để đưa vào tính toán val_acc\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, maxlen=max_length, padding='post',truncating='post')\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  y_pred_rounded = torch.round(y_pred)  \n",
    "  correct = torch.eq(y_true, y_pred_rounded).sum().item()\n",
    "  acc = (correct/len(y_pred))*100\n",
    "  return acc\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "def f1_score_fn(y_true, y_pred):\n",
    "  y_true = y_true.int()\n",
    "  y_pred = torch.round(y_pred)\n",
    "  y_pred = y_pred.int()\n",
    "  y_true=y_true.tolist()\n",
    "  y_pred = y_pred.tolist()\n",
    "  f1_score_value = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "  # print(classification_report(y_true=y_true, y_pred=y_pred,zero_division=1))  \n",
    "  return f1_score_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_encoded: np.ndarray, y_encoded: pd.core.series.Series):\n",
    "        # Setup\n",
    "        self.x_encoded = x_encoded\n",
    "        self.y_encoded = y_encoded.tolist()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.FloatTensor(self.x_encoded[idx]), self.y_encoded[idx])\n",
    "        # return (self.x_encoded[idx], self.y_encoded[idx])\n",
    "        # return {'text': self.x[idx], 'label': self.y_encoded[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_encoded.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(X_train, y_train)\n",
    "val_data = CustomDataset(X_val, y_val)\n",
    "test_data = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22542"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "class StratifiedBatchSampler:\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits=n_batches, shuffle=shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE=32\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_sampler=StratifiedBatchSampler(torch.tensor(train_data.y_encoded), batch_size=BATCH_SIZE))\n",
    "test_dataloader = DataLoader(dataset=val_data,\n",
    "                              batch_sampler=StratifiedBatchSampler(torch.tensor(val_data.y_encoded), batch_size=BATCH_SIZE))                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocal_size, embedding_dim, hidden_size, output_dim, length):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embed = nn.Embedding(num_embeddings=vocal_size, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        self.dropout_lstm = nn.Dropout(p=0.2)  # Dropout sau LSTM\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=length*hidden_size, out_features=length*hidden_size//4)\n",
    "        self.bn1 = nn.BatchNorm1d(length*hidden_size//4) \n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=length*hidden_size//4, out_features=length*hidden_size//16)\n",
    "        self.bn2 = nn.BatchNorm1d(length*hidden_size//16) \n",
    "\n",
    "        self.fc3 = nn.Linear(in_features=length*hidden_size//16, out_features=length*hidden_size//64)\n",
    "        self.bn3 = nn.BatchNorm1d(length*hidden_size//64) \n",
    "\n",
    "        self.fc4 = nn.Linear(in_features=length*hidden_size//64, out_features=output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout_lstm(x) # Áp dụng Dropout sau LSTM\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x) \n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embed): Embedding(50000, 128)\n",
       "  (lstm): LSTM(128, 32, batch_first=True)\n",
       "  (dropout_lstm): Dropout(p=0.2, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Model = LSTMModel(vocal_size=vocab_size, embedding_dim=embedding_dim,hidden_size=32, length=max_length, output_dim=1)\n",
    "LSTM_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(LSTM_Model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f865cf35584c5187fda2c43419195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "------\n",
      "\n",
      "Train loss: 0.0220, Train acc: 0.5028, F1 train score: 0.4725 | \n",
      "Test loss: 0.0232,   Test acc: 0.4548,   F1 test score: 0.4649\n",
      "Epoch: 1\n",
      "------\n",
      "\n",
      "Train loss: 0.0183, Train acc: 0.7239, F1 train score: 0.5713 | \n",
      "Test loss: 0.0207,   Test acc: 0.6249,   F1 test score: 0.5560\n",
      "Epoch: 2\n",
      "------\n",
      "\n",
      "Train loss: 0.0164, Train acc: 0.7799, F1 train score: 0.5552 | \n",
      "Test loss: 0.0188,   Test acc: 0.7174,   F1 test score: 0.5797\n",
      "Epoch: 3\n",
      "------\n",
      "\n",
      "Train loss: 0.0151, Train acc: 0.7927, F1 train score: 0.5483 | \n",
      "Test loss: 0.0171,   Test acc: 0.7430,   F1 test score: 0.5812\n",
      "Epoch: 4\n",
      "------\n",
      "\n",
      "Train loss: 0.0142, Train acc: 0.7986, F1 train score: 0.5455 | \n",
      "Test loss: 0.0163,   Test acc: 0.7470,   F1 test score: 0.5837\n",
      "Epoch: 5\n",
      "------\n",
      "\n",
      "Train loss: 0.0136, Train acc: 0.8001, F1 train score: 0.5474 | \n",
      "Test loss: 0.0154,   Test acc: 0.7452,   F1 test score: 0.5947\n",
      "Epoch: 6\n",
      "------\n",
      "\n",
      "Train loss: 0.0132, Train acc: 0.7982, F1 train score: 0.5617 | \n",
      "Test loss: 0.0149,   Test acc: 0.7446,   F1 test score: 0.6030\n",
      "Epoch: 7\n",
      "------\n",
      "\n",
      "Train loss: 0.0128, Train acc: 0.7966, F1 train score: 0.5721 | \n",
      "Test loss: 0.0146,   Test acc: 0.7279,   F1 test score: 0.6229\n",
      "Epoch: 8\n",
      "------\n",
      "\n",
      "Train loss: 0.0124, Train acc: 0.7913, F1 train score: 0.5956 | \n",
      "Test loss: 0.0143,   Test acc: 0.7275,   F1 test score: 0.6256\n",
      "Epoch: 9\n",
      "------\n",
      "\n",
      "Train loss: 0.0122, Train acc: 0.7875, F1 train score: 0.6133 | \n",
      "Test loss: 0.0135,   Test acc: 0.7426,   F1 test score: 0.6363\n"
     ]
    }
   ],
   "source": [
    "# Write a training and evaluationg loop for model_1\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Train for longer\n",
    "epochs = 10\n",
    "\n",
    "# # Put data on the target device\n",
    "# X_padded_sequences, y_train = torch.tensor(X_padded_sequences).to(device), torch.tensor(y_train).to(device)\n",
    "# padded_val_sequences, y_test=  torch.tensor(padded_val_sequences).to(device), torch.tensor(y_test).to(device)\n",
    "\n",
    "# Create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n------\")\n",
    "  ### Training\n",
    "  train_loss, train_acc=0,0\n",
    "  f1_train = []\n",
    "  cnt = 0\n",
    "  f1_score_list = []\n",
    "  LSTM_Model.train()\n",
    "  # Add a loop to loop through the training batches\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    cnt+=1\n",
    "    # 1. Forward\n",
    "    X = X.long()\n",
    "    y_pred = LSTM_Model(X)\n",
    "\n",
    "    # 2. Calculate the loss\n",
    "    loss = loss_fn(y_pred.squeeze(), y.float().squeeze())\n",
    "    train_loss += loss.item()\n",
    "    current_f1 = f1_score_fn(y_true= y.float(),\n",
    "                            y_pred = y_pred.squeeze(dim=1)).item()\n",
    "    f1_score_list.append(current_f1)\n",
    "    f1_train.append(current_f1)\n",
    "\n",
    "    # 3.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4.\n",
    "    loss.backward()\n",
    "\n",
    "    # 5.\n",
    "    optimizer.step()\n",
    "\n",
    "    # 6. Calculate accuracy metric\n",
    "    y_pred_class = torch.round(y_pred)\n",
    "    train_acc += (y_pred_class==y).sum().item()/len(y_pred_class)\n",
    "\n",
    "  # Divide total train loss by length of train dataloader\n",
    "  # train_loss\n",
    "  train_loss /= len(train_dataloader)\n",
    "  train_acc /= len(train_dataloader)\n",
    "  f1_train = sum(f1_train)/len(f1_train)\n",
    "\n",
    "  ### Testing\n",
    "  test_loss, test_acc = 0,0\n",
    "  f1_test = []\n",
    "  LSTM_Model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for batch, (X_test_, y_test_) in enumerate(test_dataloader):\n",
    "      # 1. Forward pass\n",
    "      X_test_ = X_test_.long()\n",
    "      test_pred = LSTM_Model(X_test_)\n",
    "\n",
    "      # 2. Calculate the loss (accumulatively)\n",
    "      test_loss += loss_fn(test_pred.squeeze(dim=1), y_test_.float()).item()\n",
    "      # print(test_pred.shape)\n",
    "      # 3. Calculate accuracy\n",
    "      acc = accuracy_fn(y_true= y_test_.float(),\n",
    "                        y_pred = test_pred.squeeze(dim=1))\n",
    "      acc = (torch.round(test_pred)==y_test_).sum().item()/len(y_test_)\n",
    "      test_acc += acc\n",
    "      # 4. Calculate f1 score\n",
    "      f1_test.append(f1_score_fn(y_true= y_test_.float(),\n",
    "                              y_pred = test_pred.squeeze(dim=1)).item())\n",
    "    # Calculate the test loss average per batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "    # test_loss /= len(test_dataloader)\n",
    "    f1_test = sum(f1_test)/len(f1_test)\n",
    "    # Calculate the test acc average per batch\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "  # print out what happen\n",
    "  print(f\"\\nTrain loss: {train_loss:.4f}, Train acc: {train_acc:.4f}, F1 train score: {f1_train:.4f} | \\nTest loss: {test_loss:.4f},   Test acc: {test_acc:.4f},   F1 test score: {f1_test:.4f}\")\n",
    "  # print(f\"\\nTrain loss; {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LSTM_Model.state_dict(), 'LSTM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embed.weight',\n",
       "              tensor([[-1.2278, -0.0290,  0.1851,  ...,  1.5826,  1.1992,  1.5305],\n",
       "                      [ 0.0214,  1.5840, -0.2902,  ..., -0.6611, -0.5091,  1.3219],\n",
       "                      [ 0.5880, -1.2119,  0.2408,  ...,  0.5963,  0.7509,  0.5156],\n",
       "                      ...,\n",
       "                      [-0.0787, -0.9901,  0.8272,  ..., -0.4542,  1.5091, -0.7681],\n",
       "                      [-1.2770, -0.0990, -2.4526,  ...,  0.2013, -0.2149,  0.1755],\n",
       "                      [-0.8604, -0.4840,  0.4810,  ...,  1.6619,  1.3122, -0.9310]])),\n",
       "             ('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0185, -0.0472, -0.0084,  ..., -0.0071,  0.1069, -0.0383],\n",
       "                      [ 0.0451,  0.0761, -0.1067,  ...,  0.0952, -0.0416,  0.1564],\n",
       "                      [-0.0712,  0.0067,  0.0232,  ..., -0.1420,  0.0660,  0.1597],\n",
       "                      ...,\n",
       "                      [-0.1057, -0.1789, -0.1091,  ..., -0.1048,  0.0615, -0.0185],\n",
       "                      [ 0.1228, -0.1534, -0.1028,  ...,  0.1716,  0.1212,  0.0024],\n",
       "                      [-0.0400, -0.1269,  0.0466,  ..., -0.1340,  0.1397,  0.1383]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[-0.0517,  0.0965,  0.0509,  ..., -0.0080,  0.0472,  0.0173],\n",
       "                      [ 0.0592,  0.0401,  0.0659,  ..., -0.0509,  0.0049, -0.1697],\n",
       "                      [-0.1158, -0.0023,  0.1001,  ..., -0.1498,  0.0500, -0.0654],\n",
       "                      ...,\n",
       "                      [ 0.0616, -0.1141, -0.1157,  ..., -0.1619,  0.1564, -0.0263],\n",
       "                      [-0.0709,  0.1013,  0.0243,  ..., -0.0557, -0.1013, -0.0850],\n",
       "                      [ 0.1545,  0.0392,  0.0676,  ..., -0.1081, -0.0610,  0.0112]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([ 0.1262, -0.1255,  0.0369, -0.1001,  0.1708, -0.1392, -0.0182,  0.0183,\n",
       "                       0.0081, -0.0484, -0.0793,  0.1304, -0.1123, -0.1202, -0.1170, -0.0259,\n",
       "                       0.0590, -0.0393,  0.0789, -0.0183, -0.1034,  0.0718,  0.1208, -0.1100,\n",
       "                       0.1367,  0.1052, -0.1296, -0.1300, -0.0750,  0.0092, -0.0603,  0.0902,\n",
       "                       0.0212,  0.0301,  0.1906, -0.1032, -0.1600,  0.0009, -0.0180, -0.0427,\n",
       "                       0.0747,  0.0015, -0.0031,  0.1240, -0.0498, -0.0317, -0.0599, -0.0016,\n",
       "                      -0.0833, -0.1344,  0.0553, -0.1695, -0.0211,  0.0402,  0.0067, -0.0018,\n",
       "                      -0.1787,  0.1462,  0.0061,  0.0519,  0.0644,  0.0009,  0.0095, -0.0043,\n",
       "                       0.0287,  0.0053, -0.0809,  0.0854,  0.1598, -0.0178, -0.0729,  0.0775,\n",
       "                      -0.0426,  0.1137,  0.0742, -0.1106, -0.1275,  0.1632,  0.0572,  0.0224,\n",
       "                       0.0777, -0.1269,  0.0976, -0.1692,  0.0599, -0.1190, -0.0894,  0.0753,\n",
       "                      -0.0773,  0.0344,  0.0614,  0.1646,  0.1465, -0.0296,  0.1674,  0.0802,\n",
       "                       0.1640, -0.0284, -0.1013,  0.0878,  0.1340, -0.1094,  0.0226, -0.0163,\n",
       "                      -0.0186,  0.1752,  0.0063, -0.0382, -0.0791, -0.0275,  0.1416,  0.0171,\n",
       "                       0.0155, -0.1091, -0.1124,  0.1654, -0.1202,  0.1722, -0.0209,  0.1798,\n",
       "                       0.1628, -0.0075, -0.0132,  0.1529,  0.1764,  0.0649, -0.1088,  0.1496])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.1288,  0.0514, -0.0784,  0.1103, -0.0545,  0.0364,  0.0400,  0.0251,\n",
       "                      -0.0235, -0.1114, -0.0468, -0.1211,  0.1554,  0.0472,  0.0445,  0.0434,\n",
       "                       0.0615, -0.1422, -0.0993, -0.0609,  0.1849,  0.1357,  0.0883,  0.1068,\n",
       "                       0.0795, -0.0315,  0.1443,  0.1225,  0.0971, -0.0898, -0.1026, -0.0559,\n",
       "                       0.0385,  0.0291,  0.1069,  0.1701, -0.0828, -0.0886,  0.1038, -0.0859,\n",
       "                      -0.1205, -0.1368,  0.0865, -0.1281,  0.0318, -0.1491, -0.0767,  0.0490,\n",
       "                      -0.0674, -0.1355,  0.1437,  0.0178,  0.0327,  0.0452,  0.1736, -0.1390,\n",
       "                       0.1562, -0.0874, -0.0808,  0.0860,  0.1290, -0.1427, -0.1311,  0.0501,\n",
       "                       0.0913,  0.0954,  0.0139, -0.1186,  0.0390,  0.0413,  0.0747,  0.0771,\n",
       "                       0.0573, -0.0645,  0.0246, -0.0247,  0.1114,  0.0034,  0.1144,  0.0629,\n",
       "                      -0.1596,  0.0256,  0.0689,  0.1493, -0.1390,  0.1215,  0.1338,  0.1130,\n",
       "                      -0.0151,  0.1624,  0.0377, -0.1305, -0.0164,  0.0531,  0.1720,  0.1461,\n",
       "                       0.0144,  0.0783,  0.0532,  0.1000,  0.1313, -0.1562, -0.0559,  0.0909,\n",
       "                      -0.0284, -0.0864,  0.0014, -0.1175, -0.0022, -0.1346, -0.0776, -0.1747,\n",
       "                      -0.0258,  0.0534, -0.1158, -0.0227, -0.1424,  0.1567,  0.1005,  0.1730,\n",
       "                       0.0271, -0.1622,  0.1733,  0.1064, -0.1400, -0.1282,  0.0652, -0.0792])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0016, -0.0081, -0.0037,  ..., -0.0028,  0.0064,  0.0112],\n",
       "                      [-0.0032,  0.0011,  0.0093,  ..., -0.0058,  0.0079, -0.0126],\n",
       "                      [-0.0177,  0.0015, -0.0057,  ..., -0.0126,  0.0085, -0.0019],\n",
       "                      ...,\n",
       "                      [ 0.0111,  0.0062, -0.0120,  ..., -0.0026, -0.0144,  0.0042],\n",
       "                      [-0.0047,  0.0008, -0.0115,  ..., -0.0001,  0.0070, -0.0031],\n",
       "                      [-0.0066,  0.0120, -0.0156,  ...,  0.0122, -0.0055, -0.0015]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0071, -0.0026,  0.0023,  ...,  0.0124, -0.0031,  0.0056])),\n",
       "             ('bn1.weight',\n",
       "              tensor([1.0023, 1.0033, 0.9941,  ..., 0.9989, 0.9986, 0.9987])),\n",
       "             ('bn1.bias',\n",
       "              tensor([ 0.0013,  0.0017, -0.0065,  ..., -0.0011, -0.0002, -0.0015])),\n",
       "             ('bn1.running_mean',\n",
       "              tensor([-0.1259, -0.1268,  0.0672,  ..., -0.0688, -0.1339,  0.1161])),\n",
       "             ('bn1.running_var',\n",
       "              tensor([0.0057, 0.0048, 0.0041,  ..., 0.0045, 0.0036, 0.0050])),\n",
       "             ('bn1.num_batches_tracked', tensor(7040)),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0066, -0.0099, -0.0047,  ..., -0.0240, -0.0243,  0.0036],\n",
       "                      [ 0.0109, -0.0282, -0.0074,  ..., -0.0296, -0.0035, -0.0120],\n",
       "                      [-0.0023,  0.0246,  0.0174,  ..., -0.0278, -0.0106, -0.0098],\n",
       "                      ...,\n",
       "                      [ 0.0189, -0.0007, -0.0207,  ..., -0.0185, -0.0197,  0.0279],\n",
       "                      [ 0.0284, -0.0018,  0.0290,  ...,  0.0259, -0.0268, -0.0084],\n",
       "                      [ 0.0256,  0.0026,  0.0083,  ...,  0.0049, -0.0188,  0.0195]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 4.0558e-03, -1.2046e-02, -2.4891e-02,  2.0844e-02, -2.7039e-05,\n",
       "                      -2.2690e-02,  1.6456e-02, -4.7729e-03, -1.5790e-02, -1.6979e-02,\n",
       "                       1.3588e-02, -1.4309e-02,  1.4211e-02, -2.8665e-02,  1.9262e-03,\n",
       "                      -1.5956e-02, -1.1543e-02,  1.4148e-02,  6.4588e-03,  1.4301e-02,\n",
       "                       1.5561e-02, -1.0351e-02,  1.4588e-02, -2.5015e-02,  6.9340e-03,\n",
       "                       1.6403e-02, -2.9313e-02, -1.1263e-02, -2.0845e-02,  4.8714e-03,\n",
       "                       2.5071e-02,  1.2229e-02,  1.0225e-02,  2.5221e-03,  2.7246e-02,\n",
       "                      -1.4723e-02,  2.2075e-02,  9.0805e-03, -8.6800e-03,  1.7026e-02,\n",
       "                       1.4765e-02, -1.6968e-02,  8.0193e-03, -2.3523e-03,  5.8319e-03,\n",
       "                       8.5744e-03,  2.2401e-02,  1.4604e-02,  4.3710e-03, -2.1410e-02,\n",
       "                      -1.8692e-02,  1.0992e-02,  6.3997e-03, -2.8112e-02, -2.5463e-02,\n",
       "                       2.2688e-02, -2.4037e-02,  1.0166e-02,  2.9527e-02, -6.8926e-03,\n",
       "                       3.0629e-02,  3.0165e-02,  2.8721e-02,  2.5183e-03, -3.0453e-02,\n",
       "                      -2.1159e-02, -7.6461e-04, -1.5254e-02, -2.4871e-02, -3.6500e-05,\n",
       "                      -1.6838e-02, -1.8603e-02,  6.7298e-03, -1.6910e-02,  5.5962e-03,\n",
       "                      -6.8346e-03, -1.1728e-02, -1.4714e-02,  2.7945e-02,  2.2345e-02,\n",
       "                      -2.7176e-02,  2.1018e-03,  2.7687e-02,  1.7790e-02,  1.7162e-02,\n",
       "                      -2.5690e-02,  2.3042e-02,  2.4140e-03, -4.1941e-03, -1.3668e-02,\n",
       "                       9.7722e-04,  8.5992e-03,  3.5535e-03,  7.8177e-03, -3.1230e-02,\n",
       "                      -5.8987e-03,  8.5014e-05, -4.0597e-04, -2.0439e-02, -1.3356e-02,\n",
       "                      -4.2989e-03,  1.0905e-02, -1.1986e-02,  3.4807e-03,  2.1233e-02,\n",
       "                       2.2837e-03,  9.7254e-03, -2.0009e-02, -6.0300e-03, -1.1709e-02,\n",
       "                      -1.0709e-02, -4.3389e-03, -2.2127e-02, -2.7921e-02,  2.7888e-02,\n",
       "                      -1.2424e-02, -3.0634e-02,  1.4475e-02, -2.9907e-02,  7.9841e-03,\n",
       "                       6.2270e-03, -2.0411e-02, -2.1337e-02,  5.9832e-03,  3.0693e-03,\n",
       "                       9.1129e-04, -2.2874e-02,  2.1538e-02, -2.1436e-02, -1.9809e-02,\n",
       "                       2.1704e-02, -9.7823e-03,  2.8138e-02, -1.1840e-02,  2.9809e-02,\n",
       "                      -3.0830e-02,  1.1737e-02, -1.2411e-02, -1.2430e-02,  1.4468e-02,\n",
       "                       2.4183e-02,  2.8747e-02,  2.3394e-03,  1.7970e-02,  1.2164e-02,\n",
       "                      -1.0489e-02,  1.8712e-02, -9.3354e-03, -5.1583e-03,  3.0156e-02,\n",
       "                       2.7211e-02,  2.4471e-02,  1.1715e-02,  1.1111e-02,  7.7656e-03,\n",
       "                       1.5433e-02, -1.6470e-02,  2.0192e-02, -1.3328e-02,  1.3953e-02,\n",
       "                       2.0893e-02,  6.4439e-03,  9.4845e-03,  1.0552e-02,  1.7021e-03,\n",
       "                      -2.1307e-02, -1.4768e-02, -2.0307e-02,  3.1085e-02,  2.6518e-02,\n",
       "                      -1.5235e-02,  1.9687e-03, -1.2974e-02, -4.2743e-03, -2.5846e-02,\n",
       "                      -5.4513e-03,  7.9700e-04, -1.4438e-02, -1.2614e-02,  1.0036e-02,\n",
       "                      -9.5090e-03,  2.7452e-02, -2.0534e-02, -1.8024e-02,  1.4900e-02,\n",
       "                       1.6665e-02,  2.5355e-02,  1.6504e-02,  2.7719e-02, -1.2193e-02,\n",
       "                       2.4841e-02,  2.4561e-02, -1.7808e-02, -2.8365e-02, -1.7181e-02,\n",
       "                      -1.5350e-02, -1.9427e-02, -2.4991e-02,  6.8786e-03,  1.4313e-02,\n",
       "                       6.5973e-04, -1.3190e-02, -1.4756e-02,  1.9404e-02,  8.3111e-03,\n",
       "                       2.4559e-02, -1.0548e-02,  2.5063e-02, -1.0355e-02,  5.8079e-03,\n",
       "                      -1.2269e-02,  1.9089e-02,  9.2995e-03, -2.9540e-02,  1.4622e-02,\n",
       "                       2.3902e-02,  5.5132e-03,  1.2927e-02, -3.4040e-03, -2.9559e-02,\n",
       "                      -1.0759e-02,  4.7970e-03, -1.0004e-02,  6.8729e-03, -2.6137e-02,\n",
       "                      -2.6135e-03,  2.5363e-02, -2.7579e-02, -2.7070e-02, -2.7588e-02,\n",
       "                       7.2668e-03, -6.6167e-03,  8.2996e-03,  3.0130e-02,  8.5398e-04,\n",
       "                      -1.8802e-02, -2.0395e-02, -2.3120e-03,  6.0018e-03, -2.9473e-02,\n",
       "                       2.0152e-02,  2.7284e-02,  1.2492e-02,  1.8721e-02,  8.3561e-03,\n",
       "                       3.4789e-03, -1.3191e-02,  1.1508e-02, -2.5009e-02,  1.1644e-02,\n",
       "                       1.7138e-02, -2.4213e-03,  2.3843e-02, -1.2504e-02, -1.8305e-02,\n",
       "                      -2.7361e-02])),\n",
       "             ('bn2.weight',\n",
       "              tensor([0.9981, 1.0016, 0.9995, 1.0000, 0.9969, 1.0044, 0.9984, 0.9971, 1.0001,\n",
       "                      0.9981, 0.9951, 1.0010, 0.9985, 0.9976, 0.9991, 0.9974, 1.0011, 0.9988,\n",
       "                      0.9994, 0.9986, 0.9987, 0.9986, 0.9971, 1.0025, 0.9979, 1.0010, 0.9993,\n",
       "                      1.0020, 1.0040, 1.0002, 0.9993, 1.0045, 0.9960, 1.0011, 1.0030, 0.9931,\n",
       "                      1.0006, 0.9982, 1.0020, 0.9980, 1.0010, 1.0006, 0.9975, 1.0010, 1.0016,\n",
       "                      1.0022, 0.9998, 0.9985, 0.9983, 1.0006, 1.0009, 1.0048, 1.0020, 0.9968,\n",
       "                      0.9967, 0.9961, 1.0000, 1.0045, 1.0013, 0.9988, 0.9985, 1.0019, 1.0024,\n",
       "                      0.9980, 1.0021, 0.9987, 1.0011, 1.0005, 0.9972, 1.0005, 0.9992, 0.9986,\n",
       "                      1.0024, 0.9965, 1.0027, 0.9965, 0.9998, 1.0052, 0.9977, 1.0026, 0.9993,\n",
       "                      1.0010, 0.9967, 1.0007, 0.9960, 1.0002, 1.0010, 1.0003, 0.9986, 1.0032,\n",
       "                      0.9988, 0.9989, 1.0023, 1.0022, 0.9989, 0.9998, 1.0032, 0.9979, 1.0006,\n",
       "                      0.9975, 1.0006, 1.0004, 0.9951, 1.0024, 1.0007, 1.0009, 1.0047, 0.9997,\n",
       "                      1.0022, 1.0027, 0.9936, 1.0027, 1.0005, 0.9992, 0.9997, 0.9976, 1.0024,\n",
       "                      1.0001, 1.0057, 0.9999, 0.9999, 0.9997, 0.9953, 0.9980, 1.0030, 0.9988,\n",
       "                      0.9973, 1.0026, 0.9996, 0.9977, 0.9994, 1.0024, 1.0054, 1.0036, 0.9982,\n",
       "                      0.9992, 0.9995, 1.0017, 1.0007, 1.0003, 1.0019, 1.0031, 0.9978, 1.0006,\n",
       "                      1.0010, 0.9995, 1.0040, 1.0059, 0.9999, 1.0044, 0.9952, 1.0045, 1.0011,\n",
       "                      1.0042, 0.9991, 0.9978, 0.9979, 0.9960, 0.9959, 1.0000, 0.9985, 0.9976,\n",
       "                      0.9999, 0.9997, 0.9997, 1.0045, 0.9993, 1.0009, 0.9996, 1.0068, 0.9978,\n",
       "                      1.0016, 0.9965, 1.0011, 0.9997, 0.9992, 1.0011, 1.0029, 1.0009, 0.9961,\n",
       "                      0.9972, 1.0014, 0.9986, 1.0059, 0.9999, 0.9959, 0.9974, 0.9985, 0.9989,\n",
       "                      1.0012, 1.0058, 1.0020, 0.9996, 1.0030, 1.0007, 1.0000, 1.0017, 0.9959,\n",
       "                      1.0023, 0.9972, 1.0044, 1.0031, 1.0045, 0.9987, 0.9987, 0.9977, 1.0032,\n",
       "                      0.9970, 1.0008, 1.0018, 0.9983, 1.0027, 0.9983, 1.0008, 1.0008, 1.0014,\n",
       "                      1.0070, 1.0021, 1.0035, 0.9982, 0.9985, 1.0013, 1.0065, 1.0005, 0.9986,\n",
       "                      0.9980, 0.9984, 0.9974, 0.9987, 0.9996, 1.0019, 1.0028, 0.9963, 1.0056,\n",
       "                      1.0066, 0.9973, 1.0010, 1.0015, 0.9999, 1.0014, 1.0045, 0.9967, 1.0003,\n",
       "                      0.9990, 1.0014, 1.0000, 0.9985, 1.0039, 1.0026, 1.0020, 1.0028, 1.0031,\n",
       "                      1.0004, 1.0041, 0.9983, 1.0003])),\n",
       "             ('bn2.bias',\n",
       "              tensor([-5.3306e-06,  5.3256e-04, -9.7871e-04,  9.5752e-04, -6.0594e-04,\n",
       "                       3.6271e-04, -1.0949e-03,  5.5970e-04,  3.7508e-03,  1.2308e-03,\n",
       "                      -1.2968e-03,  7.0001e-04,  1.4423e-03,  7.7555e-04, -1.0210e-03,\n",
       "                       5.3733e-04,  2.1025e-03, -6.6174e-04,  1.6746e-03, -2.1674e-04,\n",
       "                       1.4870e-03, -7.9661e-04,  9.2763e-04,  2.6398e-04, -3.0126e-03,\n",
       "                       2.5947e-03, -1.0030e-03,  2.0623e-03,  1.1723e-03, -7.9855e-04,\n",
       "                       1.2314e-03,  4.5980e-03, -8.2621e-04,  9.1516e-04,  1.3173e-03,\n",
       "                      -5.2423e-03,  6.8542e-04, -4.9943e-03, -7.9133e-04, -1.0375e-03,\n",
       "                      -2.8715e-03, -4.6103e-04, -1.0736e-03,  1.0941e-03,  5.9916e-04,\n",
       "                       1.0776e-03, -3.8814e-04,  1.8455e-04, -8.2709e-04,  6.3567e-04,\n",
       "                      -2.0716e-03,  4.6359e-03, -1.0610e-03, -1.7944e-03, -3.0199e-03,\n",
       "                      -2.4406e-03,  2.9619e-03,  2.5077e-03, -8.3139e-04, -1.3271e-03,\n",
       "                      -1.8829e-05, -4.7810e-04,  4.2817e-03, -1.2135e-03, -2.2608e-03,\n",
       "                       2.4474e-04,  3.7805e-03,  2.7596e-03, -3.0165e-03,  2.2596e-03,\n",
       "                      -1.0901e-03,  3.0725e-04,  2.3743e-03,  4.9219e-04,  1.6009e-03,\n",
       "                      -7.6944e-05,  2.6538e-03,  5.4786e-03,  6.2605e-05, -2.1071e-03,\n",
       "                       8.2086e-04,  1.4627e-03, -3.3725e-03,  8.8363e-04, -5.0131e-05,\n",
       "                      -2.6261e-03,  1.7592e-03,  1.6509e-04,  1.2610e-03,  5.0910e-03,\n",
       "                      -1.3469e-03,  3.4437e-04,  9.4459e-04,  1.5848e-03,  5.0545e-04,\n",
       "                      -1.0944e-03,  1.6521e-03, -9.5136e-04, -1.0383e-03, -1.4158e-03,\n",
       "                       2.4998e-03,  2.3615e-03, -1.1986e-03,  1.1595e-03, -1.4475e-03,\n",
       "                      -6.0918e-03,  2.2245e-03, -1.7673e-03,  2.8616e-03, -4.3648e-04,\n",
       "                      -4.6657e-03,  5.0238e-03,  1.7975e-03, -9.8014e-04,  2.3961e-03,\n",
       "                       2.2061e-03, -1.0543e-03,  3.2771e-03,  3.6300e-05, -9.4772e-05,\n",
       "                      -9.3113e-04, -1.6261e-03, -2.8220e-03,  2.3467e-03,  3.1797e-03,\n",
       "                       2.2705e-03, -3.1918e-04,  3.8465e-03, -9.0833e-04, -3.4987e-03,\n",
       "                       1.1861e-03,  2.1444e-03,  4.2260e-03,  2.3317e-03, -8.1990e-04,\n",
       "                      -3.1430e-04, -2.1166e-03,  3.7758e-03,  2.6974e-03,  1.5304e-03,\n",
       "                       4.3725e-03,  2.3794e-03, -1.5985e-03,  2.0559e-03, -3.0351e-03,\n",
       "                       1.6207e-03,  1.2369e-03,  5.3423e-03,  1.9273e-04, -6.1371e-04,\n",
       "                      -2.0098e-03,  3.4154e-03, -8.0285e-04,  3.1408e-03,  1.9944e-03,\n",
       "                      -2.7298e-03, -1.1695e-03, -1.0703e-03, -3.7671e-03,  2.0953e-03,\n",
       "                      -6.6170e-03, -5.1942e-04,  1.0320e-03,  1.6569e-03,  2.2140e-03,\n",
       "                       2.9913e-03, -1.7165e-03, -9.0430e-04,  5.4015e-05,  5.7054e-03,\n",
       "                      -1.0563e-03,  1.9219e-03, -1.0801e-03, -6.3584e-04, -1.1243e-03,\n",
       "                      -1.4600e-03,  2.3343e-03,  1.1740e-03,  2.1004e-03, -6.3641e-04,\n",
       "                      -1.9267e-03,  2.2329e-03, -8.2162e-04,  3.5761e-03, -1.4042e-03,\n",
       "                      -5.0796e-03, -1.0899e-03, -3.2234e-03,  1.5894e-03,  1.4502e-03,\n",
       "                       2.6297e-03, -3.0806e-03,  4.0489e-04,  2.2959e-03,  2.8458e-04,\n",
       "                      -1.2380e-03,  4.1045e-03, -2.5487e-03,  3.0180e-03, -6.2935e-05,\n",
       "                       2.4400e-03,  5.6115e-03,  4.3624e-03,  7.9325e-04, -2.3917e-03,\n",
       "                       8.2094e-04,  5.8007e-03, -3.1849e-04,  1.5614e-03,  1.9403e-03,\n",
       "                      -1.1241e-03,  3.0792e-03, -1.4552e-04,  1.4736e-04,  9.0213e-04,\n",
       "                       9.2167e-04,  1.9586e-03,  3.0626e-03,  3.6520e-03,  1.0358e-03,\n",
       "                      -4.0624e-03, -1.1072e-03,  3.3348e-03,  2.2935e-03,  2.6754e-03,\n",
       "                      -1.4210e-04, -7.4307e-04, -2.4159e-03, -2.2109e-03,  1.6095e-03,\n",
       "                       3.0317e-03,  4.0590e-03, -2.0916e-03,  1.4489e-03, -1.9850e-03,\n",
       "                      -1.1319e-03, -3.4779e-03,  3.5452e-03,  5.0153e-03,  1.2748e-03,\n",
       "                       3.4194e-03, -4.0639e-03,  2.4647e-03, -3.3845e-03,  2.0920e-03,\n",
       "                       1.3807e-03, -1.6885e-03,  3.1304e-03,  2.2342e-03,  3.7738e-03,\n",
       "                       2.7355e-03,  1.3012e-03,  9.8396e-04,  2.2402e-03, -9.9824e-04,\n",
       "                      -1.6479e-03])),\n",
       "             ('bn2.running_mean',\n",
       "              tensor([-3.7621e-01, -1.5565e-01,  1.2769e-01, -2.1031e-01, -1.6363e-01,\n",
       "                      -5.6753e-02,  3.5227e-03, -2.0320e-01,  3.4519e-02,  1.4702e-01,\n",
       "                      -8.7395e-02, -3.2126e-03, -3.2892e-01,  1.6861e-01,  4.5766e-01,\n",
       "                      -9.2150e-02, -4.3458e-01,  3.4590e-02,  4.2994e-01, -1.4849e-01,\n",
       "                       2.5193e-01, -1.9623e-01, -5.7054e-01,  3.8076e-01, -2.0540e-01,\n",
       "                      -5.1849e-01,  2.5891e-01,  2.7137e-01, -2.2755e-02, -5.0553e-02,\n",
       "                       1.3413e-01, -2.8790e-01,  2.3365e-02, -1.2028e-01,  4.1751e-01,\n",
       "                      -5.9736e-01, -2.3874e-01, -1.8742e-01,  6.2973e-02, -2.6185e-01,\n",
       "                      -3.7865e-02,  1.3328e-01, -6.4527e-01, -3.3129e-01, -2.8266e-01,\n",
       "                      -1.0805e-02, -9.7045e-02, -1.6016e-01,  3.0841e-02,  2.6453e-01,\n",
       "                       4.4149e-01, -2.0459e-01,  1.8199e-01, -8.2207e-02,  3.9170e-01,\n",
       "                       4.0832e-02,  2.4479e-01, -8.1636e-02, -3.6483e-01, -8.4579e-02,\n",
       "                       2.3242e-02,  3.4903e-01, -3.8421e-01,  1.5950e-01, -1.2742e-01,\n",
       "                       1.3041e-02, -1.8768e-01, -2.6390e-01, -4.5042e-01, -4.7495e-01,\n",
       "                       7.9325e-02, -3.4617e-01, -4.3052e-03, -3.6113e-02,  4.5024e-04,\n",
       "                       5.4976e-02, -3.1641e-01, -2.2079e-01,  2.0512e-01,  4.9463e-01,\n",
       "                       2.1095e-01, -2.6850e-01, -8.0072e-02,  1.7748e-01, -2.5730e-01,\n",
       "                       1.1755e-02,  2.4434e-01, -4.5930e-02, -2.0616e-01,  4.3984e-02,\n",
       "                       3.3537e-02, -2.0523e-01,  7.9709e-02, -2.4565e-01, -2.8988e-01,\n",
       "                       1.8967e-01,  1.9730e-01,  5.0174e-02, -8.9309e-02,  2.5098e-01,\n",
       "                      -2.1876e-01, -2.0667e-01,  3.4766e-02,  1.5150e-01,  2.4857e-02,\n",
       "                       2.4355e-01,  2.1511e-01,  1.3481e-02, -1.5971e-01,  1.0106e-01,\n",
       "                       2.6702e-01, -9.5725e-02, -1.9466e-01, -1.0969e-01,  5.0830e-02,\n",
       "                       8.6684e-02,  6.5595e-02, -7.6221e-03, -1.1125e-01,  3.2574e-01,\n",
       "                      -9.7206e-02, -4.2184e-01, -1.6908e-02,  9.4580e-02,  3.3461e-01,\n",
       "                      -2.7517e-02, -1.6724e-01, -2.1783e-01, -1.5589e-04, -2.4093e-01,\n",
       "                       9.9009e-02, -3.9162e-01,  3.1283e-01,  3.0587e-01, -1.0608e-01,\n",
       "                      -4.4016e-01,  6.8555e-02, -2.0173e-02, -2.3589e-02,  3.4575e-01,\n",
       "                      -3.8522e-01, -4.4177e-01, -5.4024e-02, -2.3586e-01,  1.7771e-01,\n",
       "                      -2.6592e-01,  7.0520e-02, -2.5063e-01, -1.6229e-01, -1.9890e-01,\n",
       "                      -7.4497e-02,  2.8266e-01, -1.1440e-02,  3.1522e-02,  5.1901e-01,\n",
       "                      -4.5995e-01,  9.9718e-02, -2.1606e-01,  2.8283e-02,  3.2072e-02,\n",
       "                       2.3615e-01, -1.6037e-01, -6.7403e-02,  1.7881e-01,  3.4209e-01,\n",
       "                      -3.0003e-02, -1.0683e-01,  1.2042e-01,  1.9494e-01,  2.7913e-01,\n",
       "                       6.4026e-01,  1.3759e-01, -1.1404e-01,  5.5755e-02,  3.6699e-02,\n",
       "                      -3.6191e-01, -2.8024e-01, -2.1438e-01, -4.7558e-01,  2.9454e-01,\n",
       "                      -9.2310e-02,  5.1700e-01, -9.7245e-02,  9.4830e-02, -4.2139e-03,\n",
       "                      -1.3200e-01, -2.1407e-01, -4.7517e-01,  2.6461e-01,  4.3459e-02,\n",
       "                       4.4415e-01,  2.5151e-01, -2.7868e-01, -2.5795e-01,  2.5348e-01,\n",
       "                       2.4401e-01, -3.7994e-01,  2.7398e-01,  2.8970e-01, -9.8428e-03,\n",
       "                      -9.7945e-02,  3.7560e-01, -1.3515e-01, -5.8461e-02, -5.0854e-01,\n",
       "                      -2.5289e-01,  2.9766e-01,  2.1102e-01, -3.3749e-01,  2.1968e-02,\n",
       "                       1.0833e-01, -8.3344e-02,  2.6822e-01,  5.3534e-01,  2.3641e-01,\n",
       "                      -4.7267e-01, -1.3983e-01, -1.9775e-01, -7.9298e-02, -3.3105e-01,\n",
       "                       2.7251e-01,  2.0851e-03, -1.2433e-01, -2.5695e-01,  4.1993e-01,\n",
       "                      -1.3470e-01,  1.6639e-02,  2.1952e-01,  2.5129e-01, -1.0993e-01,\n",
       "                       3.1840e-01, -3.0832e-01,  3.5473e-01, -3.1244e-01,  6.7154e-01,\n",
       "                      -2.4389e-01,  2.6167e-01,  3.0298e-01, -2.0875e-01, -2.1260e-01,\n",
       "                      -5.8462e-02, -1.5948e-01,  2.7535e-01,  4.9170e-02, -1.8831e-01,\n",
       "                      -1.3010e-01, -5.8088e-01, -1.5953e-01, -2.7314e-02, -4.7016e-02,\n",
       "                      -2.1550e-01,  5.2461e-01,  2.7141e-01, -1.6600e-01, -2.0302e-01,\n",
       "                      -4.4406e-01])),\n",
       "             ('bn2.running_var',\n",
       "              tensor([0.1820, 0.1604, 0.2292, 0.1908, 0.1708, 0.3267, 0.1700, 0.2876, 0.3461,\n",
       "                      0.2008, 0.2433, 0.1676, 0.2362, 0.2051, 0.3910, 0.2125, 0.2057, 0.2390,\n",
       "                      0.2006, 0.2017, 0.1921, 0.1560, 0.2757, 0.3100, 0.2931, 0.3204, 0.2377,\n",
       "                      0.2234, 0.2511, 0.1962, 0.2221, 0.1925, 0.2428, 0.3538, 0.2807, 0.3112,\n",
       "                      0.1845, 0.3589, 0.1751, 0.1584, 0.3115, 0.2476, 0.2835, 0.2169, 0.1849,\n",
       "                      0.1543, 0.2301, 0.2711, 0.1500, 0.1690, 0.3781, 0.2552, 0.2970, 0.2051,\n",
       "                      0.1536, 0.1649, 0.2727, 0.1867, 0.1953, 0.1995, 0.2616, 0.4752, 0.1663,\n",
       "                      0.1619, 0.2794, 0.1533, 0.2299, 0.2170, 0.1696, 0.2723, 0.3499, 0.2740,\n",
       "                      0.2198, 0.2260, 0.1986, 0.2255, 0.1954, 0.1731, 0.2606, 0.4528, 0.2037,\n",
       "                      0.1740, 0.1938, 0.1811, 0.2084, 0.1813, 0.2275, 0.2147, 0.2319, 0.1802,\n",
       "                      0.2368, 0.2500, 0.1754, 0.1957, 0.1832, 0.2062, 0.2224, 0.2846, 0.2107,\n",
       "                      0.2461, 0.2303, 0.2883, 0.2350, 0.2873, 0.3008, 0.4049, 0.2470, 0.2230,\n",
       "                      0.2122, 0.1745, 0.2713, 0.2519, 0.1672, 0.1865, 0.1820, 0.2115, 0.3059,\n",
       "                      0.2625, 0.5043, 0.3596, 0.2024, 0.1756, 0.1931, 0.1825, 0.1889, 0.3424,\n",
       "                      0.1652, 0.2043, 0.1989, 0.2235, 0.1816, 0.2619, 0.2710, 0.2164, 0.2373,\n",
       "                      0.1738, 0.2565, 0.2353, 0.1536, 0.2239, 0.3113, 0.2216, 0.1834, 0.1804,\n",
       "                      0.2779, 0.2123, 0.2256, 0.2403, 0.1810, 0.3903, 0.2195, 0.3309, 0.3456,\n",
       "                      0.1832, 0.2952, 0.2359, 0.2934, 0.2011, 0.2094, 0.2275, 0.5299, 0.1837,\n",
       "                      0.1640, 0.1628, 0.2353, 0.1914, 0.2386, 0.3097, 0.3718, 0.4522, 0.2106,\n",
       "                      0.2208, 0.1989, 0.3386, 0.1853, 0.2113, 0.2788, 0.1744, 0.2452, 0.3661,\n",
       "                      0.1817, 0.3353, 0.3050, 0.2171, 0.2752, 0.1729, 0.2003, 0.2733, 0.2128,\n",
       "                      0.1651, 0.3338, 0.4072, 0.1879, 0.1854, 0.1908, 0.2842, 0.3138, 0.1827,\n",
       "                      0.1744, 0.1867, 0.2934, 0.1917, 0.2068, 0.1896, 0.2634, 0.2882, 0.2195,\n",
       "                      0.2172, 0.2449, 0.3628, 0.2805, 0.1891, 0.2329, 0.4016, 0.1763, 0.2095,\n",
       "                      0.3672, 0.1766, 0.2391, 0.1762, 0.3105, 0.2055, 0.1825, 0.1395, 0.1788,\n",
       "                      0.1532, 0.2206, 0.2309, 0.3000, 0.2708, 0.2365, 0.1641, 0.1350, 0.3204,\n",
       "                      0.4283, 0.2789, 0.2367, 0.1963, 0.2563, 0.2246, 0.1844, 0.1557, 0.1627,\n",
       "                      0.3419, 0.2829, 0.1726, 0.2074, 0.1841, 0.2300, 0.2199, 0.1740, 0.3041,\n",
       "                      0.2178, 0.2823, 0.2246, 0.1898])),\n",
       "             ('bn2.num_batches_tracked', tensor(7040)),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0169,  0.0157,  0.0286,  ..., -0.0106, -0.0319, -0.0517],\n",
       "                      [-0.0108,  0.0018, -0.0541,  ...,  0.0522, -0.0434, -0.0168],\n",
       "                      [-0.0148,  0.0041, -0.0271,  ...,  0.0423,  0.0075, -0.0533],\n",
       "                      ...,\n",
       "                      [ 0.0360,  0.0239,  0.0124,  ..., -0.0641, -0.0143,  0.0024],\n",
       "                      [ 0.0371, -0.0394,  0.0149,  ..., -0.0471,  0.0365, -0.0570],\n",
       "                      [ 0.0580,  0.0227,  0.0007,  ..., -0.0130,  0.0561, -0.0184]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0286,  0.0344, -0.0174,  0.0382,  0.0537, -0.0434,  0.0548,  0.0330,\n",
       "                       0.0617,  0.0415, -0.0529, -0.0515, -0.0460,  0.0567, -0.0394,  0.0123,\n",
       "                       0.0589, -0.0103,  0.0493, -0.0020,  0.0397,  0.0585,  0.0089, -0.0096,\n",
       "                      -0.0465,  0.0297,  0.0164, -0.0019,  0.0529, -0.0134,  0.0256, -0.0011,\n",
       "                       0.0548, -0.0535, -0.0520,  0.0335,  0.0449,  0.0176, -0.0404, -0.0367,\n",
       "                       0.0400, -0.0124, -0.0393,  0.0450, -0.0129, -0.0261,  0.0178,  0.0474,\n",
       "                      -0.0253,  0.0185,  0.0170,  0.0117, -0.0464,  0.0474,  0.0041,  0.0356,\n",
       "                      -0.0524,  0.0093,  0.0371, -0.0507,  0.0485, -0.0320, -0.0071,  0.0331])),\n",
       "             ('bn3.weight',\n",
       "              tensor([1.0795, 1.0679, 0.9593, 0.9462, 1.0708, 1.0469, 0.9599, 1.0699, 1.0736,\n",
       "                      1.0727, 1.0780, 1.0881, 1.0384, 1.0734, 1.0672, 1.0742, 1.0862, 0.9464,\n",
       "                      1.0712, 0.9571, 0.9581, 1.0815, 1.0682, 1.0814, 1.0710, 1.0665, 1.0665,\n",
       "                      1.0701, 0.9768, 1.0134, 1.0697, 0.9549, 0.9708, 1.0170, 1.0806, 1.0741,\n",
       "                      1.0807, 0.9590, 0.9750, 1.0676, 0.9567, 1.0682, 0.9748, 1.0829, 1.0737,\n",
       "                      1.0737, 1.0260, 0.9529, 0.9561, 1.0147, 1.0690, 1.0383, 0.9474, 1.0777,\n",
       "                      1.0728, 0.9569, 1.0759, 0.9588, 1.0680, 0.9846, 1.0737, 1.0092, 0.9572,\n",
       "                      0.9559])),\n",
       "             ('bn3.bias',\n",
       "              tensor([ 0.0922,  0.0821, -0.0472, -0.0669,  0.0821,  0.0604, -0.0448,  0.0820,\n",
       "                       0.0818,  0.0835,  0.0913,  0.1070,  0.0500,  0.0843,  0.0793,  0.0865,\n",
       "                       0.1010, -0.0668,  0.0843, -0.0495, -0.0455,  0.0955,  0.0798,  0.0951,\n",
       "                       0.0824,  0.0779,  0.0808,  0.0812, -0.0275,  0.0202,  0.0847, -0.0568,\n",
       "                      -0.0290,  0.0272,  0.0978,  0.0868,  0.0939, -0.0462, -0.0235,  0.0799,\n",
       "                      -0.0502,  0.0797, -0.0246,  0.0973,  0.0835,  0.0853,  0.0349, -0.0567,\n",
       "                      -0.0515,  0.0228,  0.0825,  0.0505, -0.0648,  0.0918,  0.0857, -0.0478,\n",
       "                       0.0914, -0.0464,  0.0805, -0.0136,  0.0861,  0.0196, -0.0483, -0.0500])),\n",
       "             ('bn3.running_mean',\n",
       "              tensor([-0.3020,  0.0130,  0.3674, -0.4214, -0.0379, -0.2149,  0.4842, -0.1744,\n",
       "                      -0.2471, -0.1193,  0.0924, -0.4009, -0.0454, -0.1479,  0.2290,  0.0956,\n",
       "                      -0.0383, -0.0786, -0.0849, -0.0093,  0.2996, -0.0841, -0.0535,  0.2585,\n",
       "                       0.1135, -0.0284,  0.1523, -0.4013,  0.0056, -0.0850,  0.0160,  0.4099,\n",
       "                       0.5105,  0.1656,  0.0833, -0.2079, -0.2455,  0.5850,  0.2697, -0.2675,\n",
       "                       0.0997,  0.2625, -0.1280,  0.3786, -0.1255, -0.0421, -0.1220, -0.1989,\n",
       "                      -0.1468,  0.0629, -0.1481, -0.0897, -0.4252,  0.0691, -0.0400,  0.3535,\n",
       "                       0.0108,  0.0850, -0.2150, -0.2558, -0.3120,  0.2489,  0.3289,  0.2757])),\n",
       "             ('bn3.running_var',\n",
       "              tensor([0.1783, 0.1629, 0.4636, 0.6386, 0.2033, 0.1779, 0.6539, 0.1781, 0.5044,\n",
       "                      0.1950, 0.1512, 0.1380, 0.1773, 0.2405, 0.2400, 0.1772, 0.1783, 0.6960,\n",
       "                      0.2046, 0.5645, 0.4698, 0.1747, 0.2679, 0.2109, 0.1867, 0.2289, 0.1510,\n",
       "                      0.2787, 0.3208, 0.1830, 0.2620, 0.2717, 0.4074, 0.1691, 0.1765, 0.1611,\n",
       "                      0.1412, 0.7071, 0.2527, 0.2144, 0.2041, 0.3077, 0.1312, 0.2365, 0.2054,\n",
       "                      0.1563, 0.1315, 0.2851, 0.3863, 0.1829, 0.1569, 0.1512, 0.7518, 0.1626,\n",
       "                      0.2048, 0.5201, 0.1358, 0.6063, 0.1956, 0.1669, 0.1728, 0.1613, 0.5614,\n",
       "                      0.5199])),\n",
       "             ('bn3.num_batches_tracked', tensor(7040)),\n",
       "             ('fc4.weight',\n",
       "              tensor([[-0.0824, -0.1128,  0.0343,  0.0499, -0.1387, -0.0471,  0.0304, -0.1447,\n",
       "                       -0.1715, -0.1323, -0.0814, -0.0623, -0.0443, -0.1487, -0.1443, -0.1021,\n",
       "                       -0.0738,  0.0446, -0.1117,  0.0729,  0.0265, -0.0790, -0.1854, -0.0742,\n",
       "                       -0.1312, -0.1597, -0.0540, -0.1706, -0.0149, -0.0336, -0.1108,  0.0680,\n",
       "                       -0.0020, -0.0330, -0.0733, -0.0990, -0.0757,  0.0614, -0.0070, -0.1393,\n",
       "                        0.0261, -0.1808, -0.0087, -0.0603, -0.1293, -0.1024, -0.0389,  0.0550,\n",
       "                        0.0514, -0.0336, -0.1171, -0.0436,  0.0327, -0.0811, -0.0978,  0.0711,\n",
       "                       -0.0572,  0.0414, -0.1589, -0.0168, -0.1044, -0.0283,  0.0518,  0.0775]])),\n",
       "             ('fc4.bias', tensor([0.0108]))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model = LSTMModel(vocal_size=vocab_size, embedding_dim=embedding_dim,hidden_size=32, length=max_length, output_dim=1)\n",
    "predict_model.load_state_dict(torch.load('LSTM.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nhập câu muốn dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0135,   Test acc: 0.7427,   F1 test score: 0.6301\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = 0,0\n",
    "f1_test = []\n",
    "LSTM_Model.eval()\n",
    "for batch, (X_test_, y_test_) in enumerate(test_dataloader):\n",
    "    # 1. Forward pass\n",
    "    X_test_ = X_test_.long()\n",
    "    test_pred = LSTM_Model(X_test_)\n",
    "\n",
    "    # 2. Calculate the loss (accumulatively)\n",
    "    test_loss += loss_fn(test_pred.squeeze(dim=1), y_test_.float()).item()\n",
    "    # print(test_pred.shape)\n",
    "    # 3. Calculate accuracy\n",
    "    acc = accuracy_fn(y_true= y_test_.float(),\n",
    "                    y_pred = test_pred.squeeze(dim=1))\n",
    "    acc = (torch.round(test_pred)==y_test_).sum().item()/len(y_test_)\n",
    "    test_acc += acc\n",
    "    # 4. Calculate f1 score\n",
    "    f1_test.append(f1_score_fn(y_true= y_test_.float(),\n",
    "                            y_pred = test_pred.squeeze(dim=1)).item())\n",
    "# Calculate the test loss average per batch\n",
    "test_loss /= len(test_dataloader)\n",
    "# test_loss /= len(test_dataloader)\n",
    "f1_test = sum(f1_test)/len(f1_test)\n",
    "# Calculate the test acc average per batch\n",
    "test_acc /= len(test_dataloader)\n",
    "print(f\"Test loss: {test_loss:.4f},   Test acc: {test_acc:.4f},   F1 test score: {f1_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
