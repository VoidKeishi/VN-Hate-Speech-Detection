{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Dataset/vihsd/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free_text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ƒê√∫ng l√† b·ªçn m·∫Øt h√≠p l√≤ xo th·ª•t :))) b√™n vi·ªát n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ƒê·∫≠u VƒÉn C∆∞·ªùng gi·ªù gi·ªëng th·∫±ng sida h∆°n √†</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C√îN ƒê·ªí C·ª§C S√öC V√î NH√ÇN T√çNH ƒê·ªÄ NGHI VN. NH√Ä N∆Ø...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T·ª´ l√Ω thuy·∫øt ƒë·∫øn th·ª±c h√†nh l√† c·∫£ 1 c√¢u chuy·ªán ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           free_text  label_id\n",
       "0  Em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...         0\n",
       "1  ƒê√∫ng l√† b·ªçn m·∫Øt h√≠p l√≤ xo th·ª•t :))) b√™n vi·ªát n...         2\n",
       "2           ƒê·∫≠u VƒÉn C∆∞·ªùng gi·ªù gi·ªëng th·∫±ng sida h∆°n √†         0\n",
       "3  C√îN ƒê·ªí C·ª§C S√öC V√î NH√ÇN T√çNH ƒê·ªÄ NGHI VN. NH√Ä N∆Ø...         2\n",
       "4  T·ª´ l√Ω thuy·∫øt ƒë·∫øn th·ª±c h√†nh l√† c·∫£ 1 c√¢u chuy·ªán ...         0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_id\n",
      "0    19886\n",
      "2     2556\n",
      "1     1606\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['label_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "free_text    2\n",
       "label_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove #ERROR! values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      free_text  label_id\n",
      "1729    #ERROR!         0\n",
      "1867    #ERROR!         0\n",
      "3568    #ERROR!         0\n",
      "10788   #ERROR!         0\n",
      "11218   #ERROR!         0\n",
      "11674   #ERROR!         0\n",
      "15413   #ERROR!         0\n",
      "16080   #ERROR!         0\n",
      "18660   #ERROR!         2\n",
      "20848   #ERROR!         1\n"
     ]
    }
   ],
   "source": [
    "error_rows = train[train['free_text'].str.contains(\"#ERROR!\")]\n",
    "print(error_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train['free_text'].str.contains(\"#ERROR!\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        free_text  label_id\n",
      "225                              reaction th·∫ßy ∆°i         0\n",
      "442                    ƒë·∫∑t kh√¥ g√† ·ªü ƒë√¢u v th·∫ßy ∆°i         0\n",
      "466                              M·ªát qu√° th·∫ßy ·∫° üòû         0\n",
      "696                                         xin ·∫°         0\n",
      "790                     T·∫°i sao ph·∫£i tr·∫£ l·ªùi th·∫ßy         0\n",
      "...                                           ...       ...\n",
      "23986  ƒê√¨nh Quang ·ª•a ƒë√¢u c√≥ gi·∫£i g√¨ b√™n vn ƒëau ta         0\n",
      "23992                        Th√†nh Huy Ho√†ng Ti·∫øn         0\n",
      "24008                     T·ª± h√†o th·∫ßy Ba gold :))         0\n",
      "24010                          L·ª° tay th·∫ßy ∆°i :))         0\n",
      "24022                        Phong Chau c∆∞·ªùi ·ªâa üòÇ         0\n",
      "\n",
      "[1480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = train[train['free_text'].duplicated()]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates, keep first occurence, make changes directly to the dataframe\n",
    "train.drop_duplicates(subset='free_text', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "- Some examples have a very big length of characters, not containing helpful information. We will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_long_rows = (train['free_text'].str.len() > 500).sum()\n",
    "print(num_long_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['free_text'].str.len() <= 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              free_text  label_id\n",
      "1222  Xem ngay h·∫≠u tr∆∞·ªùng c·ª±c hi·∫øm c·ªßa c√¥ Minh Hi·∫øu ...         0\n",
      "1432  FB ch√≠nh LinDa: https://www.facebook.com/linda...         0\n",
      "1839  https://youtu.be/tvyO2B3oEYk th∆∞ gi√£n ƒë√£ c·∫£ nh...         0\n",
      "2020     @c√¥ng danh nguyen https://youtu.be/fSypgwW1L_s         0\n",
      "6891  bi·ªát th·ª± c·ªßa nude tiger: https://www.google.co...         0\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask for rows that contain a URL\n",
    "mask = train['free_text'].str.contains(r'http\\S+|www\\S+', regex=True)\n",
    "\n",
    "# Use the mask to select a subset of the DataFrame\n",
    "url_examples = train[mask]\n",
    "\n",
    "# Print the first few examples\n",
    "print(url_examples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL removal\n",
    "train['free_text'] = train['free_text'].str.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['free_text'] = train['free_text'].str.replace(r'[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords\n",
    "with open('./Stopwords/vietnamese-stopwords.txt', 'r') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# Function to remove stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# Remove stopwords from 'free_text'\n",
    "train['free_text'] = train['free_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../Dataset_Cleaned/clean_train_vihsd.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vihsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
