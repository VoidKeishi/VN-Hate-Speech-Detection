{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import emoji_vietnamese\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Load data](#load-data)\n",
    "- [Remove #ERROR! values](#remove-error-values)\n",
    "- [Remove duplicates](#remove-duplicates)\n",
    "- [Remove outliers](#remove-outliers)\n",
    "- [Remove special characters](#remove-special-characters)\n",
    "  - [URL](#remove-url)\n",
    "  - [Punctuation](#remove-punctuation)\n",
    "  - [Stopwords](#remove-stopwords)\n",
    "- [Lowercasing](#lowercasing)\n",
    "- [Emoji processing](#emoji-processing)\n",
    "- [Save cleaned data](#save-cleaned-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Dataset/vihsd/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free_text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ƒê√∫ng l√† b·ªçn m·∫Øt h√≠p l√≤ xo th·ª•t :))) b√™n vi·ªát n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ƒê·∫≠u VƒÉn C∆∞·ªùng gi·ªù gi·ªëng th·∫±ng sida h∆°n √†</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C√îN ƒê·ªí C·ª§C S√öC V√î NH√ÇN T√çNH ƒê·ªÄ NGHI VN. NH√Ä N∆Ø...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T·ª´ l√Ω thuy·∫øt ƒë·∫øn th·ª±c h√†nh l√† c·∫£ 1 c√¢u chuy·ªán ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           free_text  label_id\n",
       "0  Em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...         0\n",
       "1  ƒê√∫ng l√† b·ªçn m·∫Øt h√≠p l√≤ xo th·ª•t :))) b√™n vi·ªát n...         2\n",
       "2           ƒê·∫≠u VƒÉn C∆∞·ªùng gi·ªù gi·ªëng th·∫±ng sida h∆°n √†         0\n",
       "3  C√îN ƒê·ªí C·ª§C S√öC V√î NH√ÇN T√çNH ƒê·ªÄ NGHI VN. NH√Ä N∆Ø...         2\n",
       "4  T·ª´ l√Ω thuy·∫øt ƒë·∫øn th·ª±c h√†nh l√† c·∫£ 1 c√¢u chuy·ªán ...         0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_id\n",
      "0    19886\n",
      "2     2556\n",
      "1     1606\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['label_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "free_text    2\n",
       "label_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove #ERROR! values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      free_text  label_id\n",
      "1729    #ERROR!         0\n",
      "1867    #ERROR!         0\n",
      "3568    #ERROR!         0\n",
      "10788   #ERROR!         0\n",
      "11218   #ERROR!         0\n",
      "11674   #ERROR!         0\n",
      "15413   #ERROR!         0\n",
      "16080   #ERROR!         0\n",
      "18660   #ERROR!         2\n",
      "20848   #ERROR!         1\n"
     ]
    }
   ],
   "source": [
    "error_rows = train[train['free_text'].str.contains(\"#ERROR!\")]\n",
    "print(error_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train['free_text'].str.contains(\"#ERROR!\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        free_text  label_id\n",
      "225                              reaction th·∫ßy ∆°i         0\n",
      "442                    ƒë·∫∑t kh√¥ g√† ·ªü ƒë√¢u v th·∫ßy ∆°i         0\n",
      "466                              M·ªát qu√° th·∫ßy ·∫° üòû         0\n",
      "696                                         xin ·∫°         0\n",
      "790                     T·∫°i sao ph·∫£i tr·∫£ l·ªùi th·∫ßy         0\n",
      "...                                           ...       ...\n",
      "23986  ƒê√¨nh Quang ·ª•a ƒë√¢u c√≥ gi·∫£i g√¨ b√™n vn ƒëau ta         0\n",
      "23992                        Th√†nh Huy Ho√†ng Ti·∫øn         0\n",
      "24008                     T·ª± h√†o th·∫ßy Ba gold :))         0\n",
      "24010                          L·ª° tay th·∫ßy ∆°i :))         0\n",
      "24022                        Phong Chau c∆∞·ªùi ·ªâa üòÇ         0\n",
      "\n",
      "[1480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = train[train['free_text'].duplicated()]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates, keep first occurence, make changes directly to the dataframe\n",
    "train.drop_duplicates(subset='free_text', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "- Some examples have a very big length of characters, not containing helpful information. We will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_long_rows = (train['free_text'].str.len() > 500).sum()\n",
    "print(num_long_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['free_text'].str.len() <= 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              free_text  label_id\n",
      "1222  Xem ngay h·∫≠u tr∆∞·ªùng c·ª±c hi·∫øm c·ªßa c√¥ Minh Hi·∫øu ...         0\n",
      "1432  FB ch√≠nh LinDa: https://www.facebook.com/linda...         0\n",
      "1839  https://youtu.be/tvyO2B3oEYk th∆∞ gi√£n ƒë√£ c·∫£ nh...         0\n",
      "2020     @c√¥ng danh nguyen https://youtu.be/fSypgwW1L_s         0\n",
      "6891  bi·ªát th·ª± c·ªßa nude tiger: https://www.google.co...         0\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask for rows that contain a URL\n",
    "mask = train['free_text'].str.contains(r'http\\S+|www\\S+', regex=True)\n",
    "\n",
    "# Use the mask to select a subset of the DataFrame\n",
    "url_examples = train[mask]\n",
    "\n",
    "# Print the first few examples\n",
    "print(url_examples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL removal\n",
    "train['free_text'] = train['free_text'].str.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['free_text'] = train['free_text'].str.replace('['+string.punctuation+']', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "This could led to loss of information, so I will comment this part for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load stopwords\n",
    "# with open('./Stopwords/vietnamese-stopwords.txt', 'r') as f:\n",
    "#     stopwords = f.read().splitlines()\n",
    "\n",
    "# # Function to remove stopwords\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     words = text.split()\n",
    "#     words = [word for word in words if word not in stopwords]\n",
    "#     return ' '.join(words)\n",
    "\n",
    "\n",
    "# # Remove stopwords from 'free_text'\n",
    "# train['free_text'] = train['free_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['free_text'] = train['free_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               free_text  label_id\n",
      "0      em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...         0\n",
      "8                                                    ü•∞ü•∞ü•∞         0\n",
      "10          ƒë∆∞·ª£c anh ∆∞i l√¢u r·ªìi kh√¥ng nghe ph√∫c du rap ü§£         0\n",
      "11                      c·∫Øt cho tr·∫ª tr√¢u b·ªõt thui m√† üòÇüòÇüòÇ         0\n",
      "42                                      m·ªát qu√° th·∫ßy ·∫° üòû         0\n",
      "...                                                  ...       ...\n",
      "23995  th√¥i xong t√≥c a ch√≠ t√¥i nay l√†m vlog ƒë∆∞a djchi...         0\n",
      "24018               nguy·ªÖn loan √Ω anh √Ω l√† th·ªãt a ƒëi e üòù         0\n",
      "24034  v·ª´a l√†m chi·ªÅu nay xong ƒë√¢y  c·ª© ch·ªó uy t√≠n m√† l...         0\n",
      "24036                               cu·ªôc s√¥ng m∆∞u sinh üè¶         0\n",
      "24037             l·∫°i xui ch·ªã trang cho ƒÉn ƒë√≤n tr·∫≠n bh ü§£         0\n",
      "\n",
      "[3233 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Show emoji rows\n",
    "def show_emoji():\n",
    "    mask = train['free_text'].apply(lambda text: any(char in emoji.EMOJI_DATA for char in text))\n",
    "    # Use the mask to select a subset of the DataFrame\n",
    "    emoji_rows = train[mask]\n",
    "    return emoji_rows\n",
    "# Print the first few rows that contain an emoji\n",
    "print(show_emoji())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':m·∫∑t c∆∞·ªùi v·ªõi 3 tr√°i tim::m·∫∑t c∆∞·ªùi v·ªõi 3 tr√°i tim::m·∫∑t c∆∞·ªùi v·ªõi 3 tr√°i tim:'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demojize emojis\n",
    "train['free_text'] = train['free_text'].apply(emoji_vietnamese.demojize)\n",
    "# Show an example after demojizing\n",
    "train['free_text'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               free_text  label_id\n",
      "429                   ƒë·ªó thu·ª∑ trinh gi√¥ng y m·∫°ng nh√† m üòÄ         0\n",
      "623                             gu th·ªùi trang g·∫° ƒë·ªãt √† üòÄ         1\n",
      "667    ph∆∞∆°ng t√∫ ai bi·∫øt ng∆∞·ªùi nghe ƒë√¢u m√† m·∫•y b√†i ƒë·∫•...         0\n",
      "1278        ch·ªã cho h·ªèi  t√™n tham m·ªπ vi·ªán l√† v·∫≠y ch·ªã  üòÄüòÄ         0\n",
      "1931                   tu·∫•n b·∫£o ch·∫Øc b√°c pro h∆°n th·∫ßy üòÄüòÄ         0\n",
      "...                                                  ...       ...\n",
      "22508           ƒë√£ ƒë·∫øn l√∫c th·ª≠ ƒë·ªô b·ªÅn c·ªßa n√∫t haha r·ªìi üòÄ         0\n",
      "22939                                             h√≥ng üòÄ         0\n",
      "23217                    ph√∫c nh∆∞ng ph·ªëi nh·∫°c h·ª£p v·ªõi jüòÄ         0\n",
      "23371                                b·∫Øt n·ªôp ph·∫°t ngay üò≥         0\n",
      "23475                 phong c√°ch h·ªü rais c·ªßa ng∆∞·ªùi gi√†uüòÄ         0\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check remaining emojis\n",
    "print(show_emoji())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üò≥', '‚úã', 'üêÑ', 'üòñ', 'üòÄ', 'üò´']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See list of emojis that have not been processed\n",
    "text = ' '.join(show_emoji()['free_text'])\n",
    "emoji.distinct_emoji_list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of emoji names\n",
    "emoji_names = {\n",
    "    'üòñ': ':m·∫∑t b·ªëi r·ªëi\"',\n",
    "    'üòÄ': ':c∆∞·ªùi toe to√©t:',\n",
    "    'üò≥': ':m·∫∑t ·ª≠ng ƒë·ªè v√¨ ng∆∞·ª£ng:',\n",
    "    '‚úã': ':gi∆° tay:',\n",
    "    'üêÑ': ':con b√≤:',\n",
    "    'üò´': ':m·∫∑t m·ªát m·ªèi:'\n",
    "}\n",
    "# Replace each emoji with its name\n",
    "for emoji, name in emoji_names.items():\n",
    "    train['free_text'] = train['free_text'].str.replace(emoji, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒë·ªó thu·ª∑ trinh gi√¥ng y m·∫°ng nh√† m :c∆∞·ªùi toe to√©t:\n"
     ]
    }
   ],
   "source": [
    "# Final check\n",
    "print(train['free_text'][429])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with empty text again after processing\n",
    "train['free_text'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../Dataset_Cleaned/clean_train_vihsd.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vihsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
